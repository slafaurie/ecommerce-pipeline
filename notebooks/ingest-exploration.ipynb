{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from datetime import timedelta\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"data\"\n",
    "MAX_DELTA_TO_RANDOMIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_val_col(df):\n",
    "    #TODO add docstring\n",
    "    return {c:df[c].nunique() for c in df.columns}\n",
    "\n",
    "\n",
    "def add_root(file):\n",
    "    #TODO add docstring\n",
    "    return os.path.join(DATA_ROOT,file)\n",
    "\n",
    "\n",
    "def randomize_date_col(df, date_col, max_delta):\n",
    "    #TODO add docstring\n",
    "    df[f\"{date_col}_random\"] = df[date_col].apply(lambda x: x - timedelta(days=random.randint(1,max_delta)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def coalesce_two_cols(df, cols, new_col):\n",
    "    #TODO add docstring\n",
    "    col1, col2 = cols\n",
    "    df[new_col] = np.where(df[col1].isnull(), df[col2], df[col1])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview for file olist_closed_deals_dataset.csv\n",
      "Shape is (842, 14)\n",
      "Columns\n",
      "{'mql_id': 842, 'seller_id': 842, 'sdr_id': 32, 'sr_id': 22, 'won_date': 824, 'business_segment': 33, 'lead_type': 8, 'lead_behaviour_profile': 9, 'has_company': 2, 'has_gtin': 2, 'average_stock': 6, 'business_type': 3, 'declared_product_catalog_size': 33, 'declared_monthly_revenue': 27}\n",
      "\n",
      "Overview for file olist_customers_dataset.csv\n",
      "Shape is (99441, 5)\n",
      "Columns\n",
      "{'customer_id': 99441, 'customer_unique_id': 96096, 'customer_zip_code_prefix': 14994, 'customer_city': 4119, 'customer_state': 27}\n",
      "\n",
      "Overview for file olist_geolocation_dataset.csv\n",
      "Shape is (1000163, 5)\n",
      "Columns\n",
      "{'geolocation_zip_code_prefix': 19015, 'geolocation_lat': 717360, 'geolocation_lng': 717613, 'geolocation_city': 8011, 'geolocation_state': 27}\n",
      "\n",
      "Overview for file olist_marketing_qualified_leads_dataset.csv\n",
      "Shape is (8000, 4)\n",
      "Columns\n",
      "{'mql_id': 8000, 'first_contact_date': 336, 'landing_page_id': 495, 'origin': 10}\n",
      "\n",
      "Overview for file olist_orders_dataset.csv\n",
      "Shape is (99441, 8)\n",
      "Columns\n",
      "{'order_id': 99441, 'customer_id': 99441, 'order_status': 8, 'order_purchase_timestamp': 98875, 'order_approved_at': 90733, 'order_delivered_carrier_date': 81018, 'order_delivered_customer_date': 95664, 'order_estimated_delivery_date': 459}\n",
      "\n",
      "Overview for file olist_order_items_dataset.csv\n",
      "Shape is (112650, 7)\n",
      "Columns\n",
      "{'order_id': 98666, 'order_item_id': 21, 'product_id': 32951, 'seller_id': 3095, 'shipping_limit_date': 93318, 'price': 5968, 'freight_value': 6999}\n",
      "\n",
      "Overview for file olist_order_payments_dataset.csv\n",
      "Shape is (103886, 5)\n",
      "Columns\n",
      "{'order_id': 99440, 'payment_sequential': 29, 'payment_type': 5, 'payment_installments': 24, 'payment_value': 29077}\n",
      "\n",
      "Overview for file olist_order_reviews_dataset.csv\n",
      "Shape is (99224, 7)\n",
      "Columns\n",
      "{'review_id': 98410, 'order_id': 98673, 'review_score': 5, 'review_comment_title': 4527, 'review_comment_message': 36159, 'review_creation_date': 636, 'review_answer_timestamp': 98248}\n",
      "\n",
      "Overview for file olist_products_dataset.csv\n",
      "Shape is (32951, 9)\n",
      "Columns\n",
      "{'product_id': 32951, 'product_category_name': 73, 'product_name_lenght': 66, 'product_description_lenght': 2960, 'product_photos_qty': 19, 'product_weight_g': 2204, 'product_length_cm': 99, 'product_height_cm': 102, 'product_width_cm': 95}\n",
      "\n",
      "Overview for file olist_sellers_dataset.csv\n",
      "Shape is (3095, 4)\n",
      "Columns\n",
      "{'seller_id': 3095, 'seller_zip_code_prefix': 2246, 'seller_city': 611, 'seller_state': 23}\n",
      "\n",
      "Overview for file product_category_name_translation.csv\n",
      "Shape is (71, 2)\n",
      "Columns\n",
      "{'product_category_name': 71, 'product_category_name_english': 71}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Review columns for each file\n",
    "for f in os.listdir(DATA_ROOT):\n",
    "    df = pd.read_csv(add_root(f))\n",
    "    columns_val = get_unique_val_col(df)\n",
    "    print(f'Overview for file {f}')\n",
    "    print(f'Shape is {df.shape}')\n",
    "    print(f'Columns\\n{columns_val}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic for seller creation_date\n",
    "\n",
    "If available use won date. Otherwise, use a random date between the date of the first order for such merchant in the orders dataset and the max_delta_to_randomize parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first order date for each merchant\n",
    "orders = pd.read_csv(add_root(\"olist_orders_dataset.csv\"), \n",
    "                    parse_dates=[\"order_purchase_timestamp\"],\n",
    "                    usecols=[\"order_id\", \"order_purchase_timestamp\"]\n",
    "                    )\\\n",
    "                    .assign(purchase_date = lambda row: row[\"order_purchase_timestamp\"].dt.date)\\\n",
    "                    .loc[:,[\"order_id\", \"purchase_date\"]]\n",
    "        \n",
    "\n",
    "orders_sellers = pd.read_csv(add_root(\"olist_order_items_dataset.csv\"), usecols=[\"order_id\", \"seller_id\"])\\\n",
    "            .drop_duplicates()\n",
    "\n",
    "\n",
    "first_seller_order = orders_sellers\\\n",
    "            .merge(orders, how=\"left\", on=\"order_id\")\\\n",
    "            .groupby(\"seller_id\", as_index=False)\\\n",
    "            .agg({\"purchase_date\":\"min\"})\\\n",
    "            .rename(columns={\"purchase_date\":\"first_order_date\"})\\\n",
    "            .pipe(randomize_date_col, \"first_order_date\", MAX_DELTA_TO_RANDOMIZE)\\\n",
    "            .drop(columns=[\"first_order_date\"])\n",
    "\n",
    "seller_closed_deals = pd.read_csv(add_root(\"olist_closed_deals_dataset.csv\"), \n",
    "                                    parse_dates=[\"won_date\"], \n",
    "                                    usecols=[\"seller_id\", \"won_date\"]\n",
    "                                    )\\\n",
    "                    .assign(deal_date = lambda row: row[\"won_date\"].dt.date)\\\n",
    "                    .loc[:,[\"seller_id\", \"deal_date\"]]\n",
    "\n",
    "\n",
    "sellers_with_signupdate = pd.read_csv(add_root( \"olist_sellers_dataset.csv\"))\\\n",
    "                        .merge(first_seller_order, how=\"left\", on=\"seller_id\")\\\n",
    "                        .merge(seller_closed_deals, how=\"left\", on=\"seller_id\")\\\n",
    "                        .pipe(coalesce_two_cols, [\"deal_date\", \"first_order_date_random\"], \"signup_date\")\\\n",
    "                        .drop(columns=[\"first_order_date_random\", \"deal_date\"])\n",
    "\n",
    "\n",
    "sellers_with_signupdate.to_csv(add_root(\"olist_sellers_dataset_enriched.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship seller - order_id\n",
    "\n",
    "Relationship is not 1-1, but there are very few orders with two sellers, a 0.2%. For sake of simplicity, I'll remove those orders to enforce the 1-1 relationship so that the seller can be added to the order fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(add_root(\"olist_order_items_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total orders 98666\n",
      "number of orders with at least two different sellers 253\n"
     ]
    }
   ],
   "source": [
    "orders_with_multiple_sellers = (\n",
    "        items\n",
    "        .query('order_item_id > 1')\n",
    "        .groupby(\"order_id\", as_index=False)\n",
    "        .agg(\n",
    "            n_seller = ('seller_id', 'nunique')\n",
    "        )\n",
    "        .query(\"n_seller > 1\")\n",
    "    )\n",
    "\n",
    "print('number of total orders', items.order_id.nunique())\n",
    "print('number of orders with at least two different sellers', orders_with_multiple_sellers.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.read_csv(add_root(\"olist_orders_dataset.csv\"))\n",
    "    .merge(orders_with_multiple_sellers, on='order_id', how='left', indicator=True)\n",
    "    .query(\"_merge == 'left_only'\")\n",
    "    .drop(columns=['n_seller', '_merge'])\n",
    "    .to_csv(add_root(\"olist_orders_dataset_clean.csv\"), index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6d1a0ffc3a81bf4a66a8640965af3b38812950f48e175d6d6ccbaf96aa1fca0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
